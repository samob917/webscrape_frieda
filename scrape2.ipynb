{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79401c36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting scrape of 59 specialties\n",
      "==================================================\n",
      "\n",
      "Specialty 1/59: 336551\n",
      "------------------------------\n",
      "  Found 4 programs\n",
      "  Total collected so far: 4\n",
      "\n",
      "Specialty 2/59: 1500546\n",
      "------------------------------\n",
      "  Found 1 programs\n",
      "  Total collected so far: 5\n",
      "\n",
      "Specialty 3/59: 1500541\n",
      "------------------------------\n",
      "  Found 1 programs\n",
      "  Total collected so far: 6\n",
      "\n",
      "Specialty 4/59: 42641\n",
      "------------------------------\n",
      "  Found 92 programs\n",
      "  Total collected so far: 98\n",
      "\n",
      "Specialty 5/59: 42646\n",
      "------------------------------\n",
      "  Found 182 programs\n",
      "  Total collected so far: 280\n",
      "\n",
      "Specialty 6/59: 42896\n",
      "------------------------------\n",
      "  Found 83 programs\n",
      "  Total collected so far: 363\n",
      "\n",
      "Specialty 7/59: 294931\n",
      "------------------------------\n",
      "  Found 14 programs\n",
      "  Total collected so far: 377\n",
      "\n",
      "Specialty 8/59: 42686\n",
      "------------------------------\n",
      "  Found 145 programs\n",
      "  Total collected so far: 522\n",
      "\n",
      "Specialty 9/59: 43496\n",
      "------------------------------\n",
      "  Found 3 programs\n",
      "  Total collected so far: 525\n",
      "\n",
      "Specialty 10/59: 42701\n",
      "------------------------------\n",
      "  Found 293 programs\n",
      "  Total collected so far: 818\n",
      "\n",
      "Specialty 11/59: 43516\n",
      "------------------------------\n",
      "  Found 1 programs\n",
      "  Total collected so far: 819\n",
      "\n",
      "Specialty 12/59: 43511\n",
      "------------------------------\n",
      "  Found 3 programs\n",
      "  Total collected so far: 822\n",
      "\n",
      "Specialty 13/59: 42736\n",
      "------------------------------\n",
      "  Found 812 programs\n",
      "  Total collected so far: 1634\n",
      "\n",
      "Specialty 14/59: 43466\n",
      "------------------------------\n",
      "  Found 1 programs\n",
      "  Total collected so far: 1635\n",
      "\n",
      "Specialty 15/59: 43461\n",
      "------------------------------\n",
      "  Found 2 programs\n",
      "  Total collected so far: 1637\n",
      "\n",
      "Specialty 16/59: 42771\n",
      "------------------------------\n",
      "  Found 686 programs\n",
      "  Total collected so far: 2323\n",
      "\n",
      "Specialty 17/59: 43451\n",
      "------------------------------\n",
      "  Found 2 programs\n",
      "  Total collected so far: 2325\n",
      "\n",
      "Specialty 18/59: 43506\n",
      "------------------------------\n",
      "  Found 5 programs\n",
      "  Total collected so far: 2330\n",
      "\n",
      "Specialty 19/59: 43411\n",
      "------------------------------\n",
      "  Found 13 programs\n",
      "  Total collected so far: 2343\n",
      "\n",
      "Specialty 20/59: 43501\n",
      "------------------------------\n",
      "  Found 7 programs\n",
      "  Total collected so far: 2350\n",
      "\n",
      "Specialty 21/59: 43446\n",
      "------------------------------\n",
      "  No programs found\n",
      "\n",
      "Specialty 22/59: 43491\n",
      "------------------------------\n",
      "  Found 6 programs\n",
      "  Total collected so far: 2356\n",
      "\n",
      "Specialty 23/59: 43406\n",
      "------------------------------\n",
      "  Found 78 programs\n",
      "  Total collected so far: 2434\n",
      "\n",
      "Specialty 24/59: 1224691\n",
      "------------------------------\n",
      "  No programs found\n",
      "\n",
      "Specialty 25/59: 43456\n",
      "------------------------------\n",
      "  Found 5 programs\n",
      "  Total collected so far: 2439\n",
      "\n",
      "Specialty 26/59: 43416\n",
      "------------------------------\n",
      "  Found 15 programs\n",
      "  Total collected so far: 2454\n",
      "\n",
      "Specialty 27/59: 294936\n",
      "------------------------------\n",
      "  Found 38 programs\n",
      "  Total collected so far: 2492\n",
      "\n",
      "Specialty 28/59: 42756\n",
      "------------------------------\n",
      "  Found 46 programs\n",
      "  Total collected so far: 2538\n",
      "\n",
      "Specialty 29/59: 43471\n",
      "------------------------------\n",
      "  Found 5 programs\n",
      "  Total collected so far: 2543\n",
      "\n",
      "Specialty 30/59: 42866\n",
      "------------------------------\n",
      "  Found 123 programs\n",
      "  Total collected so far: 2666\n",
      "\n",
      "Specialty 31/59: 42876\n",
      "------------------------------\n",
      "  Found 198 programs\n",
      "  Total collected so far: 2864\n",
      "\n",
      "Specialty 32/59: 1224696\n",
      "------------------------------\n",
      "  No programs found\n",
      "\n",
      "Specialty 33/59: 42926\n",
      "------------------------------\n",
      "  Found 34 programs\n",
      "  Total collected so far: 2898\n",
      "\n",
      "Specialty 34/59: 42931\n",
      "------------------------------\n",
      "  Found 304 programs\n",
      "  Total collected so far: 3202\n",
      "\n",
      "Specialty 35/59: 336556\n",
      "------------------------------\n",
      "  Found 21 programs\n",
      "  Total collected so far: 3223\n",
      "\n",
      "Specialty 36/59: 42956\n",
      "------------------------------\n",
      "  Found 127 programs\n",
      "  Total collected so far: 3350\n",
      "\n",
      "Specialty 37/59: 42966\n",
      "------------------------------\n",
      "  Found 211 programs\n",
      "  Total collected so far: 3561\n",
      "\n",
      "Specialty 38/59: 43011\n",
      "------------------------------\n",
      "  Found 26 programs\n",
      "  Total collected so far: 3587\n",
      "\n",
      "Specialty 39/59: 43016\n",
      "------------------------------\n",
      "  Found 133 programs\n",
      "  Total collected so far: 3720\n",
      "\n",
      "Specialty 40/59: 43031\n",
      "------------------------------\n",
      "  Found 143 programs\n",
      "  Total collected so far: 3863\n",
      "\n",
      "Specialty 41/59: 43086\n",
      "------------------------------\n",
      "  Found 219 programs\n",
      "  Total collected so far: 4082\n",
      "\n",
      "Specialty 42/59: 43431\n",
      "------------------------------\n",
      "  Found 6 programs\n",
      "  Total collected so far: 4088\n",
      "\n",
      "Specialty 43/59: 43426\n",
      "------------------------------\n",
      "  Found 4 programs\n",
      "  Total collected so far: 4092\n",
      "\n",
      "Specialty 44/59: 43486\n",
      "------------------------------\n",
      "  Found 27 programs\n",
      "  Total collected so far: 4119\n",
      "\n",
      "Specialty 45/59: 43441\n",
      "------------------------------\n",
      "  Found 4 programs\n",
      "  Total collected so far: 4123\n",
      "\n",
      "Specialty 46/59: 43436\n",
      "------------------------------\n",
      "  Found 11 programs\n",
      "  Total collected so far: 4134\n",
      "\n",
      "Specialty 47/59: 43176\n",
      "------------------------------\n",
      "  Found 115 programs\n",
      "  Total collected so far: 4249\n",
      "\n",
      "Specialty 48/59: 43201\n",
      "------------------------------\n",
      "  Found 49 programs\n",
      "  Total collected so far: 4298\n",
      "\n",
      "Specialty 49/59: 43211\n",
      "------------------------------\n",
      "  Found 89 programs\n",
      "  Total collected so far: 4387\n",
      "\n",
      "Specialty 50/59: 43236\n",
      "------------------------------\n",
      "  Found 353 programs\n",
      "  Total collected so far: 4740\n",
      "\n",
      "Specialty 51/59: 43421\n",
      "------------------------------\n",
      "  Found 7 programs\n",
      "  Total collected so far: 4747\n",
      "\n",
      "Specialty 52/59: 43476\n",
      "------------------------------\n",
      "  Found 4 programs\n",
      "  Total collected so far: 4751\n",
      "\n",
      "Specialty 53/59: 43221\n",
      "------------------------------\n",
      "  Found 41 programs\n",
      "  Total collected so far: 4792\n",
      "\n",
      "Specialty 54/59: 43281\n",
      "------------------------------\n",
      "  Found 198 programs\n",
      "  Total collected so far: 4990\n",
      "\n",
      "Specialty 55/59: 43481\n",
      "------------------------------\n",
      "  Found 1 programs\n",
      "  Total collected so far: 4991\n",
      "\n",
      "Specialty 56/59: 43326\n",
      "------------------------------\n",
      "  Found 366 programs\n",
      "  Total collected so far: 5357\n",
      "\n",
      "Specialty 57/59: 43521\n",
      "------------------------------\n",
      "  Found 207 programs\n",
      "  Total collected so far: 5564\n",
      "\n",
      "Specialty 58/59: 43376\n",
      "------------------------------\n",
      "  Found 153 programs\n",
      "  Total collected so far: 5717\n",
      "\n",
      "Specialty 59/59: 43356\n",
      "------------------------------\n",
      "  Found 81 programs\n",
      "  Total collected so far: 5798\n",
      "\n",
      "==================================================\n",
      "SCRAPING COMPLETE\n",
      "Total programs collected: 5798\n",
      "Duplicates removed: 0\n",
      "Saved to: all_residency_programs.csv\n",
      "\n",
      "Programs by state (top 10):\n",
      "  NY: 567\n",
      "  CA: 531\n",
      "  FL: 381\n",
      "  TX: 375\n",
      "  PA: 350\n",
      "  MI: 305\n",
      "  OH: 281\n",
      "  IL: 231\n",
      "  NJ: 192\n",
      "  MA: 161\n",
      "\n",
      "Total runtime: 1:38:01.002190\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "def get_programs_for_specialty(spec_code, session, location_mapping):\n",
    "    \"\"\"Scrape programs for a single specialty\"\"\"\n",
    "    result_list = []\n",
    "    \n",
    "    for loc_code, states in location_mapping.items():\n",
    "        offset = 0\n",
    "        limit = 25\n",
    "        has_more = True\n",
    "        \n",
    "        while has_more:\n",
    "            # Build filter values for states\n",
    "            filter_values = \"&\".join([f\"filter[location][condition][value][]={state}\" for state in states])\n",
    "            \n",
    "            # Build API URL\n",
    "            api_url = (\n",
    "                f\"https://freida-admin.ama-assn.org/api/node/program?\"\n",
    "                f\"fields[node--program]=title,path,field_address,field_program_id,field_specialty\"\n",
    "                f\"&include=field_specialty,field_survey\"\n",
    "                f\"&page[offset]={offset}\"\n",
    "                f\"&page[limit]={limit}\"\n",
    "                f\"&filter[specialty][condition][operator]=IN\"\n",
    "                f\"&filter[specialty][condition][path]=field_specialty.drupal_internal__nid\"\n",
    "                f\"&filter[specialty][condition][value][]={spec_code}\"\n",
    "                f\"&filter[location][condition][operator]=IN\"\n",
    "                f\"&filter[location][condition][path]=field_address.administrative_area\"\n",
    "                f\"&{filter_values}\"\n",
    "                f\"&sort=-field_survey.field_first_year_positions,title\"\n",
    "            )\n",
    "            \n",
    "            try:\n",
    "                response = session.get(api_url)\n",
    "                \n",
    "                if response.status_code == 200:\n",
    "                    data = response.json()\n",
    "                    programs = data.get('data', [])\n",
    "                    \n",
    "                    if not programs:\n",
    "                        has_more = False\n",
    "                    else:\n",
    "                        for program in programs:\n",
    "                            try:\n",
    "                                attributes = program.get('attributes', {})\n",
    "                                \n",
    "                                program_info = {\n",
    "                                    'program_id': attributes.get('field_program_id', 'UNKNOWN'),\n",
    "                                    'title': attributes.get('title', 'UNKNOWN'),\n",
    "                                    'spec_code': spec_code,\n",
    "                                    'location_code': loc_code\n",
    "                                }\n",
    "                                \n",
    "                                address = attributes.get('field_address', {})\n",
    "                                program_info['state'] = address.get('administrative_area', 'UNKNOWN')\n",
    "                                program_info['city'] = address.get('locality', 'UNKNOWN')\n",
    "                                \n",
    "                                # Get detailed info\n",
    "                                if program_info['program_id'] != 'UNKNOWN':\n",
    "                                    detail_url = (\n",
    "                                        f\"https://freida-admin.ama-assn.org/api/node/program?\"\n",
    "                                        f\"filter[field_program_id]={program_info['program_id']}\"\n",
    "                                        f\"&include=field_survey.field_program_director,field_survey.field_program_contact\"\n",
    "                                    )\n",
    "                                    \n",
    "                                    detail_response = session.get(detail_url)\n",
    "                                    if detail_response.status_code == 200:\n",
    "                                        detail_data = detail_response.json()\n",
    "                                        \n",
    "                                        if 'included' in detail_data:\n",
    "                                            for item in detail_data['included']:\n",
    "                                                if item.get('type') == 'paragraph--program_individual':\n",
    "                                                    attrs = item.get('attributes', {})\n",
    "                                                    if attrs.get('parent_field_name') == 'field_program_director':\n",
    "                                                        program_info['first_name'] = attrs.get('field_first_name', 'UNKNOWN')\n",
    "                                                        program_info['last_name'] = attrs.get('field_last_name', 'UNKNOWN')\n",
    "                                                        program_info['email'] = attrs.get('field_email', 'UNKNOWN')\n",
    "                                                        addr = attrs.get('field_address', {})\n",
    "                                                        program_info['org'] = addr.get('organization', 'UNKNOWN')\n",
    "                                                        break\n",
    "                                \n",
    "                                # Fill missing fields\n",
    "                                for field in ['first_name', 'last_name', 'email', 'org']:\n",
    "                                    if field not in program_info:\n",
    "                                        program_info[field] = 'UNKNOWN'\n",
    "                                \n",
    "                                result_list.append(program_info)\n",
    "                                \n",
    "                            except Exception as e:\n",
    "                                continue\n",
    "                        \n",
    "                        offset += limit\n",
    "                        \n",
    "                        # Check for next page\n",
    "                        links = data.get('links', {})\n",
    "                        if not links.get('next'):\n",
    "                            has_more = False\n",
    "                        \n",
    "                        time.sleep(0.5)  # Rate limiting\n",
    "                else:\n",
    "                    has_more = False\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"    Error: {e}\")\n",
    "                has_more = False\n",
    "    \n",
    "    return result_list\n",
    "\n",
    "def scrape_all_residencies():\n",
    "    \"\"\"Main function to scrape all residency programs\"\"\"\n",
    "    \n",
    "    all_residencies = [\n",
    "        336551, 1500546, 1500541, 42641, 42646, 42896, 294931, 42686, 43496,\n",
    "        42701, 43516, 43511, 42736, 43466, 43461, 42771, 43451, 43506, 43411,\n",
    "        43501, 43446, 43491, 43406, 1224691, 43456, 43416, 294936, 42756,\n",
    "        43471, 42866, 42876, 1224696, 42926, 42931, 336556, 42956, 42966,\n",
    "        43011, 43016, 43031, 43086, 43431, 43426, 43486, 43441, 43436, 43176,\n",
    "        43201, 43211, 43236, 43421, 43476, 43221, 43281, 43481, 43326, 43521,\n",
    "        43376, 43356\n",
    "    ]\n",
    "    \n",
    "    location_mapping = {\n",
    "        \"01\": [\"01\", \"CT\", \"MA\", \"ME\", \"NH\", \"RI\", \"VT\"],\n",
    "        \"02\": [\"02\", \"NJ\", \"NY\"],\n",
    "        \"03\": [\"03\", \"DE\", \"MD\", \"PA\", \"VA\", \"WV\", \"DC\"],\n",
    "        \"04\": [\"04\", \"AL\", \"FL\", \"GA\", \"KY\", \"MS\", \"NC\", \"SC\", \"TN\"],\n",
    "        \"05\": [\"05\", \"IL\", \"IN\", \"MI\", \"OH\", \"WI\"],\n",
    "        \"06\": [\"06\", \"AR\", \"LA\", \"NM\", \"OK\", \"TX\"],\n",
    "        \"07\": [\"07\", \"IA\", \"KS\", \"MN\", \"MO\", \"NE\", \"ND\", \"SD\"],\n",
    "        \"08\": [\"08\", \"CO\", \"ID\", \"MT\", \"UT\", \"WY\"],\n",
    "        \"09\": [\"09\", \"AK\", \"AZ\", \"CA\", \"HI\", \"NV\", \"OR\", \"WA\"],\n",
    "        \"PR\": [\"PR\"]\n",
    "    }\n",
    "    \n",
    "    # Setup session\n",
    "    session = requests.Session()\n",
    "    session.headers.update({\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',\n",
    "        'Accept': 'application/json, text/plain, */*',\n",
    "        'Referer': 'https://freida.ama-assn.org/'\n",
    "    })\n",
    "    \n",
    "    # Master list to hold all results\n",
    "    all_results = []\n",
    "    \n",
    "    # CSV file path\n",
    "    csv_path = \"all_residency_programs.csv\"\n",
    "    \n",
    "    # Track progress\n",
    "    total_specialties = len(all_residencies)\n",
    "    \n",
    "    print(f\"Starting scrape of {total_specialties} specialties\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    for idx, spec_code in enumerate(all_residencies, 1):\n",
    "        print(f\"\\nSpecialty {idx}/{total_specialties}: {spec_code}\")\n",
    "        print(\"-\" * 30)\n",
    "        \n",
    "        try:\n",
    "            # Get programs for this specialty\n",
    "            programs = get_programs_for_specialty(spec_code, session, location_mapping)\n",
    "            \n",
    "            if programs:\n",
    "                print(f\"  Found {len(programs)} programs\")\n",
    "                all_results.extend(programs)\n",
    "                \n",
    "                # Save after each specialty (in case of crashes)\n",
    "                df = pd.DataFrame(all_results)\n",
    "                df.to_csv(csv_path, index=False)\n",
    "                print(f\"  Total collected so far: {len(all_results)}\")\n",
    "            else:\n",
    "                print(f\"  No programs found\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"  ERROR with specialty {spec_code}: {e}\")\n",
    "            continue\n",
    "        \n",
    "        # Longer delay between specialties\n",
    "        time.sleep(2)\n",
    "    \n",
    "    # Final save and summary\n",
    "    if all_results:\n",
    "        df = pd.DataFrame(all_results)\n",
    "        \n",
    "        # Remove duplicates based on program_id\n",
    "        original_count = len(df)\n",
    "        df = df.drop_duplicates(subset=['program_id'], keep='last')\n",
    "        duplicates_removed = original_count - len(df)\n",
    "        \n",
    "        # Save final CSV\n",
    "        df.to_csv(csv_path, index=False)\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 50)\n",
    "        print(\"SCRAPING COMPLETE\")\n",
    "        print(f\"Total programs collected: {len(df)}\")\n",
    "        print(f\"Duplicates removed: {duplicates_removed}\")\n",
    "        print(f\"Saved to: {csv_path}\")\n",
    "        \n",
    "        # Basic statistics\n",
    "        print(\"\\nPrograms by state (top 10):\")\n",
    "        state_counts = df['state'].value_counts().head(10)\n",
    "        for state, count in state_counts.items():\n",
    "            print(f\"  {state}: {count}\")\n",
    "    else:\n",
    "        print(\"\\nNo programs were collected\")\n",
    "\n",
    "# Run the scraper\n",
    "if __name__ == \"__main__\":\n",
    "    start_time = datetime.now()\n",
    "    scrape_all_residencies()\n",
    "    end_time = datetime.now()\n",
    "    print(f\"\\nTotal runtime: {end_time - start_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b630e8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae2f4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is for the program contact\n",
    "\n",
    "def get_programs_for_specialty(spec_code, session, location_mapping):\n",
    "    \"\"\"Scrape programs for a single specialty\"\"\"\n",
    "    result_list = []\n",
    "    \n",
    "    for loc_code, states in location_mapping.items():\n",
    "        offset = 0\n",
    "        limit = 25\n",
    "        has_more = True\n",
    "        \n",
    "        while has_more:\n",
    "            # Build filter values for states\n",
    "            filter_values = \"&\".join([f\"filter[location][condition][value][]={state}\" for state in states])\n",
    "            \n",
    "            # Build API URL\n",
    "            api_url = (\n",
    "                f\"https://freida-admin.ama-assn.org/api/node/program?\"\n",
    "                f\"fields[node--program]=title,path,field_address,field_program_id,field_specialty\"\n",
    "                f\"&include=field_specialty,field_survey\"\n",
    "                f\"&page[offset]={offset}\"\n",
    "                f\"&page[limit]={limit}\"\n",
    "                f\"&filter[specialty][condition][operator]=IN\"\n",
    "                f\"&filter[specialty][condition][path]=field_specialty.drupal_internal__nid\"\n",
    "                f\"&filter[specialty][condition][value][]={spec_code}\"\n",
    "                f\"&filter[location][condition][operator]=IN\"\n",
    "                f\"&filter[location][condition][path]=field_address.administrative_area\"\n",
    "                f\"&{filter_values}\"\n",
    "                f\"&sort=-field_survey.field_first_year_positions,title\"\n",
    "            )\n",
    "            \n",
    "            try:\n",
    "                response = session.get(api_url)\n",
    "                \n",
    "                if response.status_code == 200:\n",
    "                    data = response.json()\n",
    "                    programs = data.get('data', [])\n",
    "                    \n",
    "                    if not programs:\n",
    "                        has_more = False\n",
    "                    else:\n",
    "                        for program in programs:\n",
    "                            try:\n",
    "                                attributes = program.get('attributes', {})\n",
    "                                \n",
    "                                program_info = {\n",
    "                                    'program_id': attributes.get('field_program_id', 'UNKNOWN'),\n",
    "                                    'title': attributes.get('title', 'UNKNOWN'),\n",
    "                                    'spec_code': spec_code,\n",
    "                                    'location_code': loc_code\n",
    "                                }\n",
    "                                \n",
    "                                address = attributes.get('field_address', {})\n",
    "                                program_info['state'] = address.get('administrative_area', 'UNKNOWN')\n",
    "                                program_info['city'] = address.get('locality', 'UNKNOWN')\n",
    "                                \n",
    "                                # Get detailed info - CHANGED TO GET PROGRAM CONTACT\n",
    "                                if program_info['program_id'] != 'UNKNOWN':\n",
    "                                    detail_url = (\n",
    "                                        f\"https://freida-admin.ama-assn.org/api/node/program?\"\n",
    "                                        f\"filter[field_program_id]={program_info['program_id']}\"\n",
    "                                        f\"&include=field_survey.field_program_director,field_survey.field_program_contact\"\n",
    "                                    )\n",
    "                                    \n",
    "                                    detail_response = session.get(detail_url)\n",
    "                                    if detail_response.status_code == 200:\n",
    "                                        detail_data = detail_response.json()\n",
    "                                        \n",
    "                                        if 'included' in detail_data:\n",
    "                                            for item in detail_data['included']:\n",
    "                                                if item.get('type') == 'paragraph--program_individual':\n",
    "                                                    attrs = item.get('attributes', {})\n",
    "                                                    # CHANGED: Looking for field_program_contact instead of field_program_director\n",
    "                                                    if attrs.get('parent_field_name') == 'field_program_contact':\n",
    "                                                        program_info['contact_first_name'] = attrs.get('field_first_name', 'UNKNOWN')\n",
    "                                                        program_info['contact_last_name'] = attrs.get('field_last_name', 'UNKNOWN')\n",
    "                                                        program_info['contact_email'] = attrs.get('field_email', 'UNKNOWN')\n",
    "                                                        program_info['contact_phone'] = attrs.get('field_phone', 'UNKNOWN')  # Added phone field\n",
    "                                                        program_info['contact_title'] = attrs.get('field_title', 'UNKNOWN')  # Added title field\n",
    "                                                        addr = attrs.get('field_address', {})\n",
    "                                                        program_info['contact_org'] = addr.get('organization', 'UNKNOWN')\n",
    "                                                        break\n",
    "                                \n",
    "                                # Fill missing fields - CHANGED FIELD NAMES\n",
    "                                for field in ['contact_first_name', 'contact_last_name', 'contact_email', 'contact_phone', 'contact_title', 'contact_org']:\n",
    "                                    if field not in program_info:\n",
    "                                        program_info[field] = 'UNKNOWN'\n",
    "                                \n",
    "                                result_list.append(program_info)\n",
    "                                \n",
    "                            except Exception as e:\n",
    "                                continue\n",
    "                        \n",
    "                        offset += limit\n",
    "                        \n",
    "                        # Check for next page\n",
    "                        links = data.get('links', {})\n",
    "                        if not links.get('next'):\n",
    "                            has_more = False\n",
    "                        \n",
    "                        time.sleep(0.5)  # Rate limiting\n",
    "                else:\n",
    "                    has_more = False\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"    Error: {e}\")\n",
    "                has_more = False\n",
    "    \n",
    "    return result_list\n",
    "\n",
    "def scrape_all_residencies():\n",
    "    \"\"\"Main function to scrape all residency programs\"\"\"\n",
    "    \n",
    "    all_residencies = [\n",
    "        336551, 1500546, 1500541, 42641, 42646, 42896, 294931, 42686, 43496,\n",
    "        42701, 43516, 43511, 42736, 43466, 43461, 42771, 43451, 43506, 43411,\n",
    "        43501, 43446, 43491, 43406, 1224691, 43456, 43416, 294936, 42756,\n",
    "        43471, 42866, 42876, 1224696, 42926, 42931, 336556, 42956, 42966,\n",
    "        43011, 43016, 43031, 43086, 43431, 43426, 43486, 43441, 43436, 43176,\n",
    "        43201, 43211, 43236, 43421, 43476, 43221, 43281, 43481, 43326, 43521,\n",
    "        43376, 43356\n",
    "    ]\n",
    "    \n",
    "    location_mapping = {\n",
    "        \"01\": [\"01\", \"CT\", \"MA\", \"ME\", \"NH\", \"RI\", \"VT\"],\n",
    "        \"02\": [\"02\", \"NJ\", \"NY\"],\n",
    "        \"03\": [\"03\", \"DE\", \"MD\", \"PA\", \"VA\", \"WV\", \"DC\"],\n",
    "        \"04\": [\"04\", \"AL\", \"FL\", \"GA\", \"KY\", \"MS\", \"NC\", \"SC\", \"TN\"],\n",
    "        \"05\": [\"05\", \"IL\", \"IN\", \"MI\", \"OH\", \"WI\"],\n",
    "        \"06\": [\"06\", \"AR\", \"LA\", \"NM\", \"OK\", \"TX\"],\n",
    "        \"07\": [\"07\", \"IA\", \"KS\", \"MN\", \"MO\", \"NE\", \"ND\", \"SD\"],\n",
    "        \"08\": [\"08\", \"CO\", \"ID\", \"MT\", \"UT\", \"WY\"],\n",
    "        \"09\": [\"09\", \"AK\", \"AZ\", \"CA\", \"HI\", \"NV\", \"OR\", \"WA\"],\n",
    "        \"PR\": [\"PR\"]\n",
    "    }\n",
    "    \n",
    "    # Setup session\n",
    "    session = requests.Session()\n",
    "    session.headers.update({\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',\n",
    "        'Accept': 'application/json, text/plain, */*',\n",
    "        'Referer': 'https://freida.ama-assn.org/'\n",
    "    })\n",
    "    \n",
    "    # Master list to hold all results\n",
    "    all_results = []\n",
    "    \n",
    "    # CSV file path - CHANGED FILENAME\n",
    "    csv_path = \"all_residency_programs_contacts.csv\"\n",
    "    \n",
    "    # Track progress\n",
    "    total_specialties = len(all_residencies)\n",
    "    \n",
    "    print(f\"Starting scrape of {total_specialties} specialties (Program Contacts)\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    for idx, spec_code in enumerate(all_residencies, 1):\n",
    "        print(f\"\\nSpecialty {idx}/{total_specialties}: {spec_code}\")\n",
    "        print(\"-\" * 30)\n",
    "        \n",
    "        try:\n",
    "            # Get programs for this specialty\n",
    "            programs = get_programs_for_specialty(spec_code, session, location_mapping)\n",
    "            \n",
    "            if programs:\n",
    "                print(f\"  Found {len(programs)} programs\")\n",
    "                all_results.extend(programs)\n",
    "                \n",
    "                # Save after each specialty (in case of crashes)\n",
    "                df = pd.DataFrame(all_results)\n",
    "                df.to_csv(csv_path, index=False)\n",
    "                print(f\"  Total collected so far: {len(all_results)}\")\n",
    "            else:\n",
    "                print(f\"  No programs found\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"  ERROR with specialty {spec_code}: {e}\")\n",
    "            continue\n",
    "        \n",
    "        # Longer delay between specialties\n",
    "        time.sleep(2)\n",
    "    \n",
    "    # Final save and summary\n",
    "    if all_results:\n",
    "        df = pd.DataFrame(all_results)\n",
    "        \n",
    "        # Remove duplicates based on program_id\n",
    "        original_count = len(df)\n",
    "        df = df.drop_duplicates(subset=['program_id'], keep='last')\n",
    "        duplicates_removed = original_count - len(df)\n",
    "        \n",
    "        # Save final CSV\n",
    "        df.to_csv(csv_path, index=False)\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 50)\n",
    "        print(\"SCRAPING COMPLETE - PROGRAM CONTACTS\")\n",
    "        print(f\"Total programs collected: {len(df)}\")\n",
    "        print(f\"Duplicates removed: {duplicates_removed}\")\n",
    "        print(f\"Saved to: {csv_path}\")\n",
    "        \n",
    "        # Basic statistics\n",
    "        print(\"\\nPrograms by state (top 10):\")\n",
    "        state_counts = df['state'].value_counts().head(10)\n",
    "        for state, count in state_counts.items():\n",
    "            print(f\"  {state}: {count}\")\n",
    "            \n",
    "        # Show sample of contact data\n",
    "        print(\"\\nSample contact data (first 3 programs with contacts):\")\n",
    "        sample = df[df['contact_email'] != 'UNKNOWN'].head(3)\n",
    "        for _, row in sample.iterrows():\n",
    "            print(f\"  {row['title'][:50]}...\")\n",
    "            print(f\"    Contact: {row['contact_first_name']} {row['contact_last_name']}\")\n",
    "            print(f\"    Email: {row['contact_email']}\")\n",
    "    else:\n",
    "        print(\"\\nNo programs were collected\")\n",
    "\n",
    "# Run the scraper\n",
    "if __name__ == \"__main__\":\n",
    "    start_time = datetime.now()\n",
    "    scrape_all_residencies()\n",
    "    end_time = datetime.now()\n",
    "    print(f\"\\nTotal runtime: {end_time - start_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1673013a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
